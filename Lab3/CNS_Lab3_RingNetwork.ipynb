{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladGrigoras/CNS/blob/main/CNS_Lab3_RingNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZl1Ri63YL97"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "sns.set()\n",
        "\n",
        "# global defaults for plots - optional\n",
        "sns.set_theme(style=\"ticks\",\n",
        "              palette=\"colorblind\",\n",
        "              font_scale=1.7,\n",
        "              rc={\n",
        "              \"axes.spines.right\": False,\n",
        "              \"axes.spines.top\": False,\n",
        "          },\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ben-Yishai Ring Network"
      ],
      "metadata": {
        "id": "AS7BurNrTM2g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Grr4MkYL95"
      },
      "source": [
        "## Introduction \n",
        "The aim of this lab is to implement the ring network model which was originally proposed by [Ben-Yishai et al. (1995)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC42058/pdf/pnas01493-0220.pdf) to explain orientation tuning of neurons in visual cortex. As discussed in the lectures, this model exhibits distinct activity regimes in which orientation tuning \n",
        "is determined by:\n",
        "\n",
        "1. The tuning of feedforward inputs to the neurons.\n",
        "2. Recurrent synapses within the V1 circuit.\n",
        "\n",
        "Due to the behaviour of the ring model in the recurrent-dominated regime, it has since been adopted as a model for persistent activity of neurons observed in brain areas such as prefrontal cortex during the delay period of working memory tasks. \n",
        "\n",
        "In the following exercises you will implement the model as a numerical simulation, vary the parameters in order to simulate the\n",
        "different regimes of the model, explore the behaviour of the model in each regime and think about possible implications of your findings for orientation tuning in visual cortex and for working memory in prefrontal cortex."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "### Continuous neuron\n",
        "The original model consists of a continuous ring of rate neurons which are parameterised by their preferred orientation $\\theta\\in (-\\pi/2,\\pi/2)$, as a featureless bar can only have distinguishable orientations in the range $-90^\\circ$ to $+90^\\circ$.\n",
        "\n",
        "The dynamics of the model is defined as,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\tau \\frac{dr (\\theta, t)}{dt}&=-r(\\theta, t) + [h(\\theta, t)]_{+}  \\hspace{1cm}(1)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $[x]_{+}=x$ if $x>0$ and $0$ otherwise, that is the ReLU activation function. The net input is,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "h(\\theta, t) &= u(\\theta-\\theta_s)+\\int_{-\\pi/2}^{\\pi/2} W(\\theta,\\theta')r(\\theta',t)d\\theta ' \\hspace{1cm}(2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\theta_s$ is the stimulus orientation. The recurrent weights are,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "W(\\theta,\\theta') &= A + B \\cos(2(\\theta-\\theta'))\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "and the feedforward external input,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "u(\\theta-\\theta_s) = C + D \\cos(2(\\theta-\\theta_s)) = c[1-\\epsilon+\\epsilon\\cos(2(\\theta-\\theta_s))]\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where the second parameterisation of the input is interpreted as a stimulus contrast parameter $c$ and tuning strength parameter $\\epsilon$.\n",
        "\n",
        "### Discretisation\n",
        "This formulation of the model as a continuous network was chosen by Ben-Yishai et al. because it can be solved analytically to find the steady state responses. However, for running simulations we need to convert the model into a network of N discrete neurons as follows: \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\tau \\frac{dr_i (t)}{dt}&=-r_i(t) + [h_i(t)]_{+}\n",
        "\\\\h_i(t) &= u_i+\\frac{1}{N}\\sum_{j=1}^N W_{ij}r_j(t)\n",
        "\\\\W_{ij}&=W_0 + W_1\\cos (2(\\theta_i-\\theta_j))\n",
        "\\\\u_i&=c[1-\\epsilon + \\epsilon \\cos(2(\\theta_i-\\theta_s))]\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where neurons are indexed over a discrete set of angles $\\theta_i=i\\pi/N-\\pi/2$.\n"
      ],
      "metadata": {
        "id": "uCyAPlzAbU1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation of the System\n",
        "This section is dedicated to implementing the dynamical system and how to evaluate it."
      ],
      "metadata": {
        "id": "36h89n7m-oM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise 1 $-$ Implementation of Functions\n",
        "\n",
        "Write code to implement the right hand side of each of the above equations."
      ],
      "metadata": {
        "id": "9AJ6AW3vQIzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the functions:\n",
        "\n",
        "def generate_u(N, Nt, c, epsilon, theta, theta_s): \n",
        "  '''\n",
        "  inputs\n",
        "  N: number of neurons\n",
        "  Nt: number of time steps \n",
        "  c, epsilon: input parameters\n",
        "  theta: N dimensional ndarray of preferred orientations\n",
        "  thea_s: stimulus orientation\n",
        "\n",
        "  output\n",
        "  u: NtxN dimensional ndarray of inputs across time\n",
        "  '''\n",
        "\n",
        "  u = np.zeros([Nt,N])\n",
        "  \n",
        "  return '...'\n",
        "\n",
        "def h(r,u,W,t):\n",
        "  '''\n",
        "  inputs\n",
        "  r: N dimensional ndarray \n",
        "  u: NtxN dimensional ndarray\n",
        "  W: NxN dimensional ndarray\n",
        "  t: time point\n",
        "\n",
        "  output\n",
        "  h: N dimensional ndarray\n",
        "  '''\n",
        "\n",
        "  return '...'\n",
        "\n",
        "def dr_dt(r,u,W,tau,t):\n",
        "  '''\n",
        "  inputs\n",
        "  r: N dimensional ndarray \n",
        "  u: NtxN dimensional ndarray\n",
        "  W: NxN dimensional ndarray\n",
        "  tau: time constant\n",
        "  t: time point\n",
        "\n",
        "  output\n",
        "  dr_dt: N dimensional ndarray\n",
        "  '''\n",
        "\n",
        "  return '...'\n",
        "\n",
        "\n",
        "def generate_W(N, W0, W1, theta): \n",
        "  '''\n",
        "  inputs\n",
        "  N, W0, W1: model parameters (int)\n",
        "  theta: N dimensional ndarray\n",
        "\n",
        "  output\n",
        "  W: NxN dimensional ndarray\n",
        "  '''\n",
        "  \n",
        "  W = np.zeros([N,N])\n",
        "\n",
        "  return '...'"
      ],
      "metadata": {
        "id": "N44SSvxNVGL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the system\n",
        "To simulate the dynamics in time, we will use the Euler method which we have implemented below. It works for any dynamical system that can be represented as $\\dot{\\bf{x}}=f(\\bf{x},t)$."
      ],
      "metadata": {
        "id": "JjMwZv2bJGbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euler(f,x0,Nt,dt):\n",
        "  \"\"\"\n",
        "  in:\n",
        "  f : RHS of the differential equation (dx(x)/dt), takes x as an input\n",
        "  x0 : initial state\n",
        "  dt : step size\n",
        "  Nt : number of steps\n",
        "\n",
        "  out:\n",
        "  xt : an Nt+1 x len(x) matrix of the state of the system over time\n",
        "  \"\"\"\n",
        "\n",
        "  xt = np.zeros([Nt+1, len(x0)])\n",
        "  xt[0] = x0\n",
        "\n",
        "  for i in range(1,Nt+1):\n",
        "    xt[i] = xt[i-1]+dt*f(xt[i-1],i-1)\n",
        "\n",
        "  return xt"
      ],
      "metadata": {
        "id": "xG7rmyEaC7-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper functions\n",
        "We define a function to simulate one run for the Ben-Yishai ring network with a time-dependent input, using the Euler method and starting from an initial condition $r_{init}$."
      ],
      "metadata": {
        "id": "2XJxSSE_OLHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BY_ring_network(r_init, W, u, tau, Nt, dt): \n",
        "\n",
        "    def F(r,i):\n",
        "      \n",
        "      return dr_dt(r,u,W,tau,i)\n",
        "\n",
        "    rt = euler(F,r_init,Nt,dt)\n",
        "    \n",
        "    return rt"
      ],
      "metadata": {
        "id": "fjssJFKzOsmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation with Different Regimes\n",
        "\n",
        "To get a first impression for how the networks behave in their default settings, we next simulate and plot the activity of the network in three different regimes. "
      ],
      "metadata": {
        "id": "UsC4cp63Q72G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default parameters\n",
        "As default parameters we set:\n",
        "\n",
        "\n",
        "*  $N=100$ the number discrete neurons\n",
        "*  $\\tau=10$ms the time constant of the network\n",
        "*  $\\theta_s = 0$ the stimulus orientation\n",
        "*  $c=0.5$ the external input strength (or stimulus contrast)\n",
        "*  $\\Delta t=1$ the time discretisation\n",
        "\n",
        "The values for $\\epsilon,W_0,W_1$ depend on the simulated regime and are defined in subsequent sections."
      ],
      "metadata": {
        "id": "4W_U8MDAT7m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 100\n",
        "tau_m = 10\n",
        "theta_s = 0\n",
        "c = 0.5\n",
        "dt = 1\n",
        "\n",
        "theta_p = np.linspace(-np.pi/2, np.pi/2, N+1)[:N]"
      ],
      "metadata": {
        "id": "hR_962yNAyPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bRvvYA4YL99"
      },
      "source": [
        "## Exercise 2.1 $-$ Hubel and Wiesel regime\n",
        "In the Hubel and Wiesel regime, the network is driven by strongly tuned feedforward inputs and there is no recurrent connectivity. To model this, set $W_0$ = 0, $W_1 = 0$ so that $h_i (t) = u_i$. As the input is strongly tuned, $\\epsilon$ is high. Set $\\epsilon$ = 1. \n",
        "\n",
        "1. What do you expect the steady state to look like in this regime? Write the steady state equation for $r_i$ from equation (1) and sketch the response you expect to the inputs $u_i$.\n",
        "\n",
        "Then, run the cell below and compare your prediction with the numerical results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6l9PBUrYL99"
      },
      "outputs": [],
      "source": [
        "Nt = 500\n",
        "epsilon = 1\n",
        "W_HW = generate_W(N, 0, 0, theta_p)\n",
        "u = generate_u(N, Nt, c, epsilon, theta_p, theta_s)\n",
        "\n",
        "output = BY_ring_network(np.zeros(N), W_HW, u, tau_m, Nt, dt)\n",
        "\n",
        "fig, ax = plt.subplots(1,2,  figsize = (20,5))\n",
        "sns.heatmap(output.T, ax = ax[0], xticklabels = 100, yticklabels = 20)\n",
        "ax[0].set_yticklabels(ax[0].get_yticklabels(), rotation=0)\n",
        "ax[0].set_title('Network output')\n",
        "ax[0].set_xlabel('Time (ms)')\n",
        "ax[0].set_ylabel('Neuron')\n",
        "\n",
        "ax[1].plot(np.degrees(theta_p), output[-1], label = '$r_i$')\n",
        "ax[1].plot(np.degrees(theta_p), u[-1], label = '$u_{i}$')\n",
        "ax[1].set_title('Steady state response')\n",
        "ax[1].set_ylabel('Network output')\n",
        "ax[1].set_xlabel('Preferred orientation ($^\\circ$)')\n",
        "ax[1].legend(bbox_to_anchor=(1., 1.0), loc='upper left', fontsize = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2.2 $-$ Uniform Inhibition regime\n",
        "\n",
        "The uniform inhibition regime was not discussed in lectures, but was included in the original paper of Ben-Yishai et al. This regime is defined by the uniform mutual inhibition between all neurons. This means that the recurrent weights are negative and do not differ around the ring. Therefore, set $W_0 = −1$ and $W_1 = 0$. \n",
        "\n",
        "1. As an exercise plot 1) the response at steady state and 2) the feedforward input $u_i$, for values of $\\epsilon$ as low as 0.01 and as high as 1. \n",
        "2.   How does $\\epsilon$ influence the results? Why do you think this happens?\n",
        "3.   For the experiments section below, pick $\\epsilon = 1$ when simulating the non-uniform regime (you can also explore the consequences of varying it if you like)."
      ],
      "metadata": {
        "id": "f6JuZDEkQ0bP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "t_bwsArfYL9-"
      },
      "outputs": [],
      "source": [
        "Nt = 500\n",
        "epsilons = np.linspace(0.01, 1, 4)   # try a range of different values for the input tuning parameter\n",
        "\n",
        "# Complete with the appropriate inputs to the function\n",
        "W_UI = generate_W(...)\n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2.3 $-$ Marginal Regime\n",
        "\n",
        "The above two regimes assume that the external input is strongly tuned and that recurrent input is either absent or uniform. Another theory is that the tuning of the inputs themselves is very weak, but is amplified by non-uniform interactions within the network. This regime is called the recurrent-dominated regime, or the “marginal” regime, which is a terminology inherited from models for spontaneous symmetry breaking in statistical physics. \n",
        "\n",
        "1. To model this case, set the external input tuning $\\epsilon$ to be small (e.g. 0.01), and set the connections to be strongly dependent on the preferred orientations of their pre- and post-synaptic\n",
        "neurons by choosing $W_0 = −1$, $W_1 = 3$. Simulate and plot as above.\n",
        "\n",
        "2. Try varying $\\epsilon$ to even smaller values (or larger ones), and investigate how this influences the profile of the network response and the input profile $u_i$."
      ],
      "metadata": {
        "id": "bRA5e9JyRG-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f96d9UAFYL9_"
      },
      "outputs": [],
      "source": [
        "Nt = 500\n",
        "epsilons = np.linspace(0.01, 1, 4) #try varying this\n",
        "\n",
        "# Complete with the appropriate inputs to the function\n",
        "W_MR = generate_W(...) \n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare weight matrices\n",
        "\n",
        "To visualise how the weight matrices look like for the different regimes, we plotted them next to each other below*: the marginal regime is the only regime where the weight matrix shows any structure.  \n",
        "\n",
        "*Note that the code below will work only if the variables names `W_HW`, `W_UI`, `W_MR` were left unchanged in the previous cells"
      ],
      "metadata": {
        "id": "SlxYk50E27oD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhatFfB1YL9_"
      },
      "outputs": [],
      "source": [
        "Ws = [W_HW, W_UI, W_MR]\n",
        "regimes = ['Hubel and Wiesel', 'Uniform inhibition', 'Marginal Regime']\n",
        "\n",
        "fig, ax = plt.subplots(1,len(Ws), figsize = (20,5))\n",
        "\n",
        "for i in range(len(Ws)):\n",
        "  ax[i] = sns.heatmap(Ws[i], vmin = -4, vmax = 2, ax = ax[i], xticklabels = 20, yticklabels = 20)\n",
        "  ax[i].set_yticklabels(ax[i].get_yticklabels(), rotation=0)\n",
        "  ax[i].set_ylabel('Neuron')\n",
        "  ax[i].set_xlabel('Neuron')\n",
        "  ax[i].set_title(regimes[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "The following experiments are designed to reveal how the behaviour of the ring network differs between each of the above regimes. Run each experiment for the Hubel and Wiesel, uniform inhibition and marginal regime. For experiments involving changes in stimuli (rotation or deletion), make sure that the network has settled/stabilised prior to changing the stimulus."
      ],
      "metadata": {
        "id": "If6uxT5lRRuy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgP_njyYL9_"
      },
      "source": [
        "## Exercise 3.1 $-$ Stimulus Rotation\n",
        "\n",
        "* Once the activity has settled under the presentation of a stimulus at $\\theta_s = 0$, rotate the stimulus by $60$ degrees. \n",
        "  1. How do you expect the activity to change after the rotation?\n",
        "  2. How do you think the change of activity depends on the network regime? \n",
        "  3. Do you think the behaviour would differ if you rotate the stimulus\n",
        "by different angles?\n",
        "\n",
        "* Examine the time course of the network activity in response to this stimulus rotation and compare the simulations with your predictions.\n",
        "\n",
        "There are two different possibilities on how to use the function BY_ring_network() to collect the results of a stimulus rotation. You can either define your stimulus for one whole simulation, so that the stimulus in itself already is changing (as shown below). Or you can run two seperate simulations with two different stimuli and use the last timepoint of the 1st simulation (using the 1st stimulus) as `r_init` for the second simulation (using the 2nd stimulus), as shown below for the stimulus deletion experiments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "1yEpRIcZYL9_"
      },
      "outputs": [],
      "source": [
        "Nt = 5000\n",
        "\n",
        "epsilon_HW = 1\n",
        "epsilon_UI = 1\n",
        "epsilon_MR = 0.01\n",
        "\n",
        "theta_s_1sthalf = 0\n",
        "theta_s_2ndhalf = np.pi/3 # 60 degrees rotation\n",
        "\n",
        "epsilons = [epsilon_HW, epsilon_UI, epsilon_MR]\n",
        "Ws = [W_HW, W_UI, W_MR]\n",
        "network_names = ['Hubel and Wiesel regime', 'Uniform Inhibition', 'Marginal Regime']\n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3.2 $-$ Stimulus Deletion\n",
        "\n",
        "We next present a stimulus with orientation $\\theta_s = 0$. Once the activity has settled, the stimulus is deleted by setting $u_i = c$. \n",
        "\n",
        "1. How does the response following the deletion of the stimulus depend on the regime of the model? \n",
        "2. In which network regime could you decode the stimulus orientation after the stimulus has been deleted?"
      ],
      "metadata": {
        "id": "ofEWFsI_Ra29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "kKrtYcPlYL-A"
      },
      "outputs": [],
      "source": [
        "Nt = 5000\n",
        "\n",
        "epsilon_HW = 1\n",
        "epsilon_UI = 1\n",
        "epsilon_MR = 0.01\n",
        "\n",
        "\n",
        "theta_s = 0\n",
        "\n",
        "epsilons = [epsilon_HW, epsilon_UI, epsilon_MR]\n",
        "Ws = [W_HW, W_UI, W_MR]\n",
        "network_names = ['Hubel and Wiesel regime', 'Uniform Inhibition', 'Marginal Regime']\n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noisy Inputs\n",
        "\n",
        "As discussed in the lectures, neural activity is noisy. For the following experiments the total background noise is modelled as an additive Gaussian variable. Therefore we define $u_i (t)$ as:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "u_i(t)&=c[1-\\epsilon+\\epsilon \\cos(2\\theta)]+\\sigma \\eta_i(t)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\eta_i(t) \\sim \\mathcal{N}(0,1)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "with $\\sigma$ the magnitude of the noise (remember that this depends on the discretisation timestep when numerically integrating). To simulate, draw $\\eta_i$ independently for each neuron at each timestep."
      ],
      "metadata": {
        "id": "JwbmUQwsVRFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.1 $-$ Persistent Noisy Input\n",
        "\n",
        "Simulate all three model regimes with the newly defined noisy input $u_i (t)$, and with different choices for $\\sigma$. \n",
        "1. How does the noise change the responses of the networks? \n",
        "2. Is there a network which is more robust to noise than the others? \n",
        "3. Try simulating the marginal regime but now with completely untuned inputs ($\\epsilon = 0$). How does noise influence the response of the network? \n",
        "4. Compare with noise values ranging from $\\sigma = 0.05$ to $σ = 1$. What do you think is happening? How does increasing $\\epsilon$ change the results?"
      ],
      "metadata": {
        "id": "jpYQUm9PReUh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfewN2E-YL-A"
      },
      "outputs": [],
      "source": [
        "def generate_noisy_u(N, Nt, c, epsilon, theta, theta_s, sigma, rseed = 1, dt = 1): \n",
        "    \n",
        "    u = np.zeros([Nt,N])\n",
        "    rng = np.random.RandomState(seed = rseed)\n",
        "    \n",
        "    #Complete the code here:\n",
        "    u[:] = '...'\n",
        "    \n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JgENWAnTYL-A"
      },
      "outputs": [],
      "source": [
        "epsilon_HW = 1\n",
        "epsilon_UI = 1\n",
        "epsilon_MR = 0.01\n",
        "\n",
        "theta_s = 0\n",
        "\n",
        "epsilons = [epsilon_HW, epsilon_UI, epsilon_MR, 0]\n",
        "Ws = [W_HW, W_UI, W_MR, W_MR]\n",
        "\n",
        "network_names = ['Hubel and Wiesel regime', 'Uniform Inhibition', 'Marginal Regime', 'Marginal Regime - untuned input']\n",
        "\n",
        "sigmas = np.linspace(0.05, 1, 4)\n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.2 $-$ Noisy Input After Stimulus Deletion\n",
        "\n",
        "Next we repeat the stimulus-deletion experiment, but this time include the persistent noisy input described above. Once the stimulus is deleted, the external input should be $u_i (t) = c+\\eta_i (t)$. \n",
        "\n",
        "1. What happens in each regime? \n",
        "2. How would the noisy input influence the ability to decode the stimulus orientation after the stimulus has been deleted? \n",
        "3. How might this be relevant when modelling working memory?"
      ],
      "metadata": {
        "id": "vcwqjdRbRlM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QaleCfZYL-B"
      },
      "outputs": [],
      "source": [
        "def generate_untuned_noisy_u(N, Nt, c, sigma, rseed = 1, dt = 1): \n",
        "    \n",
        "    u  = np.zeros([Nt,N])\n",
        "    rng = np.random.RandomState(seed = rseed)\n",
        "    \n",
        "    #Complete the code for the untuned input (after stimulus deletion)\n",
        "    u[:] = '...'\n",
        "    \n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "EopqvZkOYL-B"
      },
      "outputs": [],
      "source": [
        "epsilon_HW = 1\n",
        "epsilon_UI = 1\n",
        "epsilon_MR = 0.01\n",
        "\n",
        "sigma = 0.2\n",
        "\n",
        "theta_s = 0\n",
        "network_names = ['Hubel and Wiesel regime', 'Uniform Inhibition', 'Marginal Regime']\n",
        "\n",
        "epsilons = [epsilon_HW, epsilon_UI, epsilon_MR]\n",
        "Ws = [W_HW, W_UI, W_MR]\n",
        "\n",
        "# Your solution here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus Section: Derivation of the Tuning Curves (Optional)\n",
        "\n",
        "In this section, we will derive the expression for the tuning curve of the neurons in the ring network. \n",
        "\n",
        "We consider the discrete version of the equations and the case where the stimulus is $\\theta_s=0$ to simplify notation. The steady state of (the discretised) equation (1) is $r^*_i$, which represents the activity profile of the network relative to the orientation of the stimulus. Thus, it also represents the tuning curve of a neuron, centred at its preferential orientation.\n",
        "\n",
        "The solution for the steady state is given by the equation $r^*_i = [h^*_i]_+$, where $h^*_i$ is given by equation (2) and is in the form:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "h^*_i &= c[1-\\epsilon + \\epsilon \\cos(2\\theta_i)] + \\frac{1}{N}\\sum_{j=1}^N [W_0 + W_1\\cos(2(\\theta_i-\\theta_j)]r^*_j \\hspace{1cm}(S1)\\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "To find the solution for $r^*_i$, we need to move to the Fourier space. For an even function $r_j$ with $j\\in[1,N]$ (we drop the $^*$ notation for now), we can write $r_j$ as a Fourier series of cosines:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "r_j &= \\sum_{k=0}^{N-1} \\hat{r}_k \\cos\\left(\\frac{2\\pi}{N}kj\\right),  \\hspace{1cm}(S2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\hat{r}_k$ are the Fourier coefficients of $r_j$. Note that the following orthogonality relation holds:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{1}{N}\\sum_{j=1}^{1}\\cos\\left(\\frac{2\\pi}{N}kj\\right)\\cos\\left(\\frac{2\\pi}{N}k'j\\right) = \\delta_{k,k'}. \\hspace{1cm}(S3)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "1. Substitute eq. (S2) into eq. (S1) to simplify it in terms of Fourier coefficients. [Use the property in eq (S3) and note that $\\theta_j = j2\\pi/N$]\n",
        "\n",
        "\n",
        "2. Now write the full equation for the steady state by substituing the previous equation for $h^*_i$ into $r^*_i = [h^*_i]_+$ and finding an equation for each coefficient. [Note that you will have to expand $r^*_i$ into the Fourier series]\n"
      ],
      "metadata": {
        "id": "3HjwoapsmYQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[Ben-Yishai, R., Bar-Or, R. L., & Sompolinsky, H. (1995). Theory of orientation tuning in visual cortex. Proceedings of the National Academy of Sciences, 92(9), 3844-3848. ](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC42058/)"
      ],
      "metadata": {
        "id": "VZ7HAxnbRwr2"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}